---
layout: post
title: 騙徒以人工智能換臉換聲詐騙　警籲留意視像眼神口型
date: 2023-07-03 08:36:14.000000000 +08:00
link: https://news.rthk.hk/rthk/ch/component/k2/1707242-20230703.htm
categories: rthk
---

警方表示，留意到近幾個月，有騙徒懷疑借助人工智能深偽技術製作虛假新聞報道，推介投資活動，或冒充名人移花接木後製影片，引誘市民參與不存在的投資計劃；網上亦有人討論，利用相關技術實時換臉換聲，透過視像通話假冒受害人親友要求匯款。

警方又指，不法分子透過社交平台的公開影像，大量套取冒充對象的聲音和臉部訊息，再透過深偽技術製作影片，在視像通話中播放，騙徒之後會利用各種藉口完結通話，再要求受害人轉換到其他即時通訊軟件繼續對話，從而繼續詐騙行為。

警方早前接獲情報，指一名身在外地的日籍人士在社交平台一個假冒某銀行管理層的帳戶中，瀏覽一條提及香港投資計劃的影片並信以為真，並向騙徒轉帳價值港幣1700元的點數卡；亦有情報指，有人懷疑利用深偽技術進行恐嚇，有市民經交友平台認識左騙徒，根據指示下載手機軟件，進行短暫視像通話後，發現樣貌被移花接木到色情片段，繼而被騙徒勒索，該名市民因感到懷疑，最終未有受騙。

警方網絡安全組高級督察陳智穎說，深偽技術並非完美，市民可以留意影片中的人物眼神和口型是否有不自然的地方，也可以要求對方在鏡頭面前舉起手指並橫向移動，或將頭部上下左右轉動，由於電腦需要針對突如其來改變重新運算，影片質素會受影響，繼而露出破綻，破解詐騙手法。

警方網絡安全及科技罪案調查科網絡安全組警司陳純青說，「眼見不一定為實，有圖亦不一定是真相」，提醒市民保持警惕及查證。警方又提醒，市民切勿接聽陌生視像電話，以免聲音和樣貌等個人生物辨識資料被盜取作深偽技術影片，再進行詐騙。
